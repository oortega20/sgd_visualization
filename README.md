<script
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
  type="text/javascript">
</script>

# sgd_visualization

When taking machine learning courses, I was always fascinated with gradient descent algorithms such as SGD.
I always loved the analogy of the ball moving down the hill and how this analogy can be expressed in a mathematically rigorous way using tools such as multi-variable calculus. 
I did this project simply because I like to see this analogy visually. In the future, I plan to incorporate other gradient based optimization methodologies onto this visualization project to get a comparison of their performance. 
Also, the only thing better than a ball rolling down a hill is many balls rolling down a hill :).

# Algorithm
Defined simply, gradient descent is an algorithm that from a starting vector 

$$
x_{n+1}
$$


Enjoy,


Oscar Ortega

![](https://github.com/oortega20/sgd_visualization/blob/master/sgd.gif)
